{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing twint\n",
    "Installing twint will install all related packages (like numpy,etc) that makes twint function properly.\n",
    "\n",
    "### Upgrading twint\n",
    "For those who already have twint and wish to upgrade it due to certain functionality not working, or any other reasons, run the uninstall command first.\n",
    "\n",
    "Otherwise, for a fresh install, you may skip running the code below and start from the second cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: twint 2.1.20\n",
      "Uninstalling twint-2.1.20:\n",
      "  Successfully uninstalled twint-2.1.20\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip3 uninstall twint --yes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/twintproject/twint.git@origin/master\n",
      "  Cloning https://github.com/twintproject/twint.git (to revision origin/master) to /private/var/folders/1j/w13pmgjd6r59876tb75jxls80000gn/T/pip-req-build-_lb73rkj\n",
      "  Running command git clone -q https://github.com/twintproject/twint.git /private/var/folders/1j/w13pmgjd6r59876tb75jxls80000gn/T/pip-req-build-_lb73rkj\n",
      "\u001b[33m  WARNING: Did not find branch or tag 'origin/master', assuming revision or ref.\u001b[0m\n",
      "  Running command git checkout -q origin/master\n",
      "Requirement already satisfied, skipping upgrade: aiohttp in /Users/pcowe/opt/anaconda3/lib/python3.7/site-packages (from twint==2.1.21) (3.7.3)\n",
      "Requirement already satisfied, skipping upgrade: aiodns in /Users/pcowe/opt/anaconda3/lib/python3.7/site-packages (from twint==2.1.21) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: beautifulsoup4 in /Users/pcowe/opt/anaconda3/lib/python3.7/site-packages (from twint==2.1.21) (4.8.0)\n",
      "Requirement already satisfied, skipping upgrade: cchardet in /Users/pcowe/opt/anaconda3/lib/python3.7/site-packages (from twint==2.1.21) (2.1.7)\n",
      "Collecting dataclasses\n",
      "  Using cached dataclasses-0.6-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied, skipping upgrade: elasticsearch in /Users/pcowe/opt/anaconda3/lib/python3.7/site-packages (from twint==2.1.21) (7.11.0)\n",
      "Requirement already satisfied, skipping upgrade: pysocks in /Users/pcowe/opt/anaconda3/lib/python3.7/site-packages (from twint==2.1.21) (1.7.1)\n",
      "Requirement already satisfied, skipping upgrade: pandas in /Users/pcowe/opt/anaconda3/lib/python3.7/site-packages (from twint==2.1.21) (0.25.1)\n",
      "Requirement already satisfied, skipping upgrade: aiohttp_socks in /Users/pcowe/opt/anaconda3/lib/python3.7/site-packages (from twint==2.1.21) (0.5.5)\n",
      "Requirement already satisfied, skipping upgrade: schedule in /Users/pcowe/opt/anaconda3/lib/python3.7/site-packages (from twint==2.1.21) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: geopy in /Users/pcowe/opt/anaconda3/lib/python3.7/site-packages (from twint==2.1.21) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: fake-useragent in /Users/pcowe/opt/anaconda3/lib/python3.7/site-packages (from twint==2.1.21) (0.1.11)\n",
      "Requirement already satisfied, skipping upgrade: googletransx in /Users/pcowe/opt/anaconda3/lib/python3.7/site-packages (from twint==2.1.21) (2.4.2)\n",
      "Requirement already satisfied, skipping upgrade: yarl<2.0,>=1.0 in /Users/pcowe/opt/anaconda3/lib/python3.7/site-packages (from aiohttp->twint==2.1.21) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=17.3.0 in /Users/pcowe/opt/anaconda3/lib/python3.7/site-packages (from aiohttp->twint==2.1.21) (19.2.0)\n",
      "Requirement already satisfied, skipping upgrade: multidict<7.0,>=4.5 in /Users/pcowe/opt/anaconda3/lib/python3.7/site-packages (from aiohttp->twint==2.1.21) (5.1.0)\n",
      "Requirement already satisfied, skipping upgrade: async-timeout<4.0,>=3.0 in /Users/pcowe/opt/anaconda3/lib/python3.7/site-packages (from aiohttp->twint==2.1.21) (3.0.1)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.5 in /Users/pcowe/opt/anaconda3/lib/python3.7/site-packages (from aiohttp->twint==2.1.21) (3.7.4.3)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4.0,>=2.0 in /Users/pcowe/opt/anaconda3/lib/python3.7/site-packages (from aiohttp->twint==2.1.21) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: pycares>=3.0.0 in /Users/pcowe/opt/anaconda3/lib/python3.7/site-packages (from aiodns->twint==2.1.21) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: soupsieve>=1.2 in /Users/pcowe/opt/anaconda3/lib/python3.7/site-packages (from beautifulsoup4->twint==2.1.21) (1.9.3)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<2,>=1.21.1 in /Users/pcowe/opt/anaconda3/lib/python3.7/site-packages (from elasticsearch->twint==2.1.21) (1.24.2)\n",
      "Requirement already satisfied, skipping upgrade: certifi in /Users/pcowe/opt/anaconda3/lib/python3.7/site-packages (from elasticsearch->twint==2.1.21) (2019.9.11)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /Users/pcowe/opt/anaconda3/lib/python3.7/site-packages (from pandas->twint==2.1.21) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /Users/pcowe/opt/anaconda3/lib/python3.7/site-packages (from pandas->twint==2.1.21) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /Users/pcowe/opt/anaconda3/lib/python3.7/site-packages (from pandas->twint==2.1.21) (1.17.2)\n",
      "Requirement already satisfied, skipping upgrade: python-socks[asyncio]>=1.0.1 in /Users/pcowe/opt/anaconda3/lib/python3.7/site-packages (from aiohttp_socks->twint==2.1.21) (1.2.1)\n",
      "Requirement already satisfied, skipping upgrade: geographiclib<2,>=1.49 in /Users/pcowe/opt/anaconda3/lib/python3.7/site-packages (from geopy->twint==2.1.21) (1.50)\n",
      "Requirement already satisfied, skipping upgrade: requests in /Users/pcowe/opt/anaconda3/lib/python3.7/site-packages (from googletransx->twint==2.1.21) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: idna>=2.0 in /Users/pcowe/opt/anaconda3/lib/python3.7/site-packages (from yarl<2.0,>=1.0->aiohttp->twint==2.1.21) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: cffi>=1.5.0 in /Users/pcowe/opt/anaconda3/lib/python3.7/site-packages (from pycares>=3.0.0->aiodns->twint==2.1.21) (1.12.3)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /Users/pcowe/opt/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas->twint==2.1.21) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: pycparser in /Users/pcowe/opt/anaconda3/lib/python3.7/site-packages (from cffi>=1.5.0->pycares>=3.0.0->aiodns->twint==2.1.21) (2.19)\n",
      "Building wheels for collected packages: twint\n",
      "  Building wheel for twint (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for twint: filename=twint-2.1.21-py3-none-any.whl size=38760 sha256=e07ff87bfe6cad5c2b948cca583b2cd4bd3a38fc2bdd9d8b37661cb02d9eca27\n",
      "  Stored in directory: /private/var/folders/1j/w13pmgjd6r59876tb75jxls80000gn/T/pip-ephem-wheel-cache-zjln_dgb/wheels/8d/dc/9f/74b4483d5f997036f04aec7f42bd4b3c80f04264920c368068\n",
      "Successfully built twint\n",
      "Installing collected packages: dataclasses, twint\n",
      "\u001b[33m  WARNING: The script twint is installed in '/Users/pcowe/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed dataclasses-0.6 twint-2.1.21\n",
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/Users/pcowe/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --user --upgrade git+https://github.com/twintproject/twint.git@origin/master #egg=twint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nest_asyncio\n",
      "  Downloading nest_asyncio-1.5.1-py3-none-any.whl (5.0 kB)\n",
      "Installing collected packages: nest-asyncio\n",
      "Successfully installed nest-asyncio-1.5.1\n",
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/Users/pcowe/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-0.15.0-py2.py3-none-any.whl (18 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-0.15.0\n",
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/Users/pcowe/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages\n",
    "Importing modules and essential packages for running this notebook :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, csv, math\n",
    "# Basic utilities for processing data in python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Open source Twitter intelligence tool\n",
    "import twint\n",
    "# Twitter authentication client\n",
    "from twitterclient import get_twitter_client\n",
    "# Twitter API client\n",
    "import tweepy\n",
    "from tweepy import Cursor\n",
    "# Removes runtimeError in jupyterlab -> This event loop is already running\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find network actors using twint\n",
    "Use the cell below to gather information/data about different search queries, hasthags, etc to identify which actors and conversations you wish to study.\n",
    "\n",
    "All data from this section will be stored in '/search queries' folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'twint' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8d7de8124aa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Configure twint query parameters to find all users talking about FSL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mqp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtwint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mqp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSearch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"French as a second language\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mqp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data/search queries/fsl-terms.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'twint' is not defined"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "# Configure twint query parameters to find all users talking about FSL\n",
    "\n",
    "qp = twint.Config()\n",
    "qp.Search = \"French as a second language\"\n",
    "qp.Output = \"data/search queries/fsl-terms.csv\"\n",
    "qp.Store_csv = True\n",
    "\n",
    "# Run twint on configured qp\n",
    "\n",
    "twint.run.Search(qp)\n",
    "print(\"Running search query\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract username list of network actors\n",
    "In this step we need to identify all actors that we will include in the network we are going to study. To do this, we will extract usernames from all the files created in the /search queries folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "MAX_FRIENDS = 15000\n",
    "client = get_twitter_client()\n",
    "max_pages = math.ceil(MAX_FRIENDS/ 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup paginate function\n",
    "def paginate(items, n):\n",
    "    \"\"\"\n",
    "    Generate n-sized chunks from Items\n",
    "\n",
    "    \"\"\"\n",
    "    for i in range(0, len(items), n):\n",
    "        yield items[i:i+n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open csv file to extract column names\n",
    "with open('data/search queries/fsl-terms.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    columnNames = []\n",
    "    for row in csv_reader:\n",
    "        columnNames.append(row)\n",
    "        #break after reading first row\n",
    "        break\n",
    "columnNames = columnNames[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pcowe/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (0,1,5,6,9,15,16,17,21,23,25,26,27,28,29,30,32,33,34,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Todo: Add code to extract list of username from multiple csv files\n",
    "\n",
    "data = pd.read_csv('data/search queries/fsl-terms.csv', names=columnNames)\n",
    "usernames = data.username.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enbikawa\n"
     ]
    }
   ],
   "source": [
    "print(usernames[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Edges\n",
    "\n",
    "In the next part I will create directed edges from our network of users. This is directed because we are goimg to represent followers/following relationships for each user in our general group of users.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweepy error occured: Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Max retries exceeded with url: /1.1/users/lookup.json (Caused by SSLError(SSLError(\"bad handshake: SysCallError(54, 'ECONNRESET')\"))). Skipped adding user: anyechka\n"
     ]
    }
   ],
   "source": [
    "# make sure you are not repeating already scraped users. You will waste time\n",
    "# for this, check your network-progress list for users you already have scraped and remove them from usernames \n",
    "\n",
    "# load updated username list before you continue to build your network \n",
    "\n",
    "progress_params = ['explored_users', 'skipped_users']\n",
    "network_progress = pd.read_csv('data/network/network-progress.csv', names=progress_params)\n",
    "explored_users = network_progress.explored_users.tolist()\n",
    "skipped_users = network_progress.skipped_users.tolist()\n",
    "# ignoring the nan's and column names, len(explored) + len(skipped) = len(usernames) \n",
    "unames = [ x for x in usernames if x not in (explored_users + skipped_users)]\n",
    "\n",
    "#loop through all users and write their followers to csv\n",
    "try:\n",
    "    \n",
    "    for user in unames:\n",
    "        \n",
    "\n",
    "        fname = \"data/network/network-edges.csv\"\n",
    "        fieldnames = ['From', 'To']\n",
    "        with open(fname, 'a') as f:\n",
    "\n",
    "            csv_writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "\n",
    "            # get a user's followers list\n",
    "            for followers in Cursor(client.followers_ids, screen_name=user).pages(max_pages):\n",
    "                for chunk in paginate(followers, 100):\n",
    "                    userFollowers = client.lookup_users(user_ids=chunk)\n",
    "\n",
    "                    for follower in userFollowers:\n",
    "\n",
    "                        #print(len(users))\n",
    "\n",
    "                        #print(follower.screen_name)\n",
    "                        csv_writer.writerow({'From': follower.screen_name, 'To': user})\n",
    "\n",
    "                    # f.write(json.dumps(user._json)+\"\\n\")\n",
    "                if len(followers) == 5000:\n",
    "                    print(\"More results available. Sleeping for 60 seconds to avoid rate limit\")\n",
    "                    time.sleep(60)\n",
    "\n",
    "            # get a user's following list\n",
    "            for friends in Cursor(client.friends_ids, screen_name=user).pages(max_pages):\n",
    "\n",
    "                for chunk in paginate(friends, 100):\n",
    "                    userFollowing = client.lookup_users(user_ids=chunk)\n",
    "                    for followed in userFollowing:\n",
    "                        csv_writer.writerow({'From': user, 'To': followed.screen_name})\n",
    "                if len(friends) == 5000:\n",
    "                    print(\"More results available. Sleeping for 60 seconds to avoid rate limit\")\n",
    "                    time.sleep(60)\n",
    "\n",
    "            f.close()\n",
    "            \n",
    "            # Update network-progress\n",
    "            with open('data/network/network-progress.csv', 'a') as nprog:\n",
    "                nprog_updater = csv.DictWriter(nprog, fieldnames=progress_params)\n",
    "                nprog_updater.writerow({'explored_users': user, 'skipped_users': ' '})\n",
    "                nprog.close()\n",
    "            \n",
    "except tweepy.TweepError as err:\n",
    "    \n",
    "    \n",
    "    print(\"Tweepy error occured: {}. Skipped adding user: {}\".format(err, user))\n",
    "    with open('data/network/network-progress.csv', 'a') as nprog:\n",
    "        nprog_updater = csv.DictWriter(nprog, fieldnames=progress_params)\n",
    "        nprog_updater.writerow({'explored_users': ' ', 'skipped_users': user})\n",
    "        nprog.close()\n",
    "    pass\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Nodes\n",
    "\n",
    "In the next part I will create nodes from our network actors. \n",
    "\n",
    "### Optional\n",
    "Add code to include specific node attributes to enhance network visualization in gephi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code for representing nodes in nodes.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
